{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCbAmQ47iqK4"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "    \n",
        "# FIT5196 Task 1 in Assessment 1\n",
        "#### Student Name: Emmanuelle Christin; Phakhanan Rataphaibul\n",
        "#### Student ID: 32941943; 33654735\n",
        "\n",
        "Date: 16 March 2024\n",
        "\n",
        "\n",
        "Environment: Python 3.10.12\n",
        "\n",
        "Libraries used:\n",
        "* re (for regular expression, installed and imported)\n",
        "* pandas (for data manipulation)\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjBFqYK4iqK5"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\">\n",
        "    \n",
        "## Table of Contents\n",
        "\n",
        "</div>    \n",
        "\n",
        "[1. Introduction](#Intro) <br>\n",
        "[2. Importing Libraries](#libs) <br>\n",
        "[3. Examining Patent Files](#examine) <br>\n",
        "[4. Loading and Parsing Files](#load) <br>\n",
        "$\\;\\;\\;\\;$[4.1. Defining Regular Expressions](#Reg_Exp) <br>\n",
        "$\\;\\;\\;\\;$[4.2. Reading Files](#Read) <br>\n",
        "$\\;\\;\\;\\;$[4.3. Whatever else](#latin) <br>\n",
        "[5. Writing to CSV/JSON File](#write) <br>\n",
        "$\\;\\;\\;\\;$[5.1. Verification - using the sample files](#test_xml) <br>\n",
        "[6. Summary](#summary) <br>\n",
        "[7. References](#Ref) <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcbqK3KliqK6"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEFdSCIUiqK6"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "## 1.  Introduction  <a class=\"anchor\" name=\"Intro\"></a>\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGg4-8VSiqK6"
      },
      "source": [
        "This assessment regards extracting data from semi-structured text files related to a subset of records on trademark assignments. The dataset is a `.txt` file stored in XML format, each representing a unique trademark assignment. In particular, each text file is recorded with a set of attributes such as reel no, frame no, correspondent party, assignors, assignee, and properties. The primary objective of this assessment is to extract, parse, and transform these semi-structured text files into JSON format which is a more structured and analyzable format.\n",
        "\n",
        "Key tasks in this assessment involve:\n",
        "\n",
        "1. Examining raw data from the .txt files to understand the structure and identify patterns for different data elements.\n",
        "2. Parsing the data using regular expressions (re library) to extract specific patterns and information from the semi-structured text files across all fields.\n",
        "3. Further processing the extracted data from step 2 to refine the required fields according to the specified requirements and save the data into a proper format.\n",
        "4. Writing the processed data to a JSON output file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6Ql-W6BiqK7"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnctlBF6iqK7"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    \n",
        "## 2.  Importing Libraries  <a class=\"anchor\" name=\"libs\"></a>\n",
        " </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQOLlwmAiqK7"
      },
      "source": [
        "The packages to be used in this assessment are imported in the following. They are used to fulfill the following tasks:\n",
        "\n",
        "* **re:** is imported to define and use regular expressions in Python. In this assessment, regular expressions (regex) are utilized for defining patterns and extracting specific data from XML files. Regular expressions are used to match and extract various elements such as assignment details, correspondent information, assignor and assignee details, and properties information from the structured XML data.\n",
        "* **json:**  is imported to handle JSON (JavaScript Object Notation) data in Python. JSON is a lightweight and human-readable data interchange format commonly used for transmitting and storing data objects. In the context of this assessment, the json library is utilized to work with JSON data. Specifically, it is used to write JSON data to a file in a structured and formatted manner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mKGO6FAXiqK7"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wMWqFiW4jewp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bbb87ad-dd69-4b4c-e989-6f9dfd476c5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DEWD9qIiqK8"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "Z814ttFYiqK8"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "## 3.  Examining Raw Data <a class=\"anchor\" name=\"examine\"></a>\n",
        "\n",
        " </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gp3TG3fyiqK9"
      },
      "source": [
        "First of all, understanding the structure and content of the raw data is necessary for extracting meaningful information. Having examined the file content, the following observations were made:\n",
        "\n",
        "- Most data entries do not have date-acknowledged field.\n",
        "- A single correspondent may have up to four addresses listed.\n",
        "- There can be many assignors, assignees, and properties.\n",
        "- A single assignor/assignee can have multiple addresses.\n",
        "- The field 'nationality' is sometimes specified with a state or city name instead of a country name.\n",
        "- Similarly, the field 'country-name' is also specified with a state or city name instead of the actual country name\n",
        "- Some organization names include titles such as 'Mr.' within the name.\n",
        "- When the 'legal-entity-text' field of an assignor/assignee is set to 'INDIVIDUAL', the 'person-or-organization-name' field will contain a person's name. Conversely, when it is set to 'CORPORATION', the 'person-or-organization-name' field will contain an organization's name\n",
        "- Some fields contain special character such as French name in 'legal-entity-text'.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBEASWLfiqK-"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "iDoVeDSHiqK-"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "## 4.  Loading and Parsing Files <a class=\"anchor\" name=\"load\"></a>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z24HaN8hiqK-"
      },
      "source": [
        "This section consists of three main processes. We start by defining appropriate regular expressions to extract necessary fields from the XML content. We then parse the file using the defined regular expressions and functions, finally and transform the parsed data into JSON format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ0tuwvZiqK-"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rApp_Ic9iqK-"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "### 4.1. Defining Regular Expressions <a class=\"anchor\" name=\"Reg_Exp\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knauV0VViqK-"
      },
      "source": [
        "In this step, we define a set of regular expressions for extracting all necessary fields from the XML content. These patterns are designed to match various elements within the XML structure, including details regarding assignment entries such as reel numbers, frame numbers, and last updated dates, and details concerning correspondents, assignors, assignees, and property-related information."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Regular expression patterns to extract data from XML content\n",
        "assg_entry_pattern = r'<assignment-entry>(.*?)</assignment-entry>' # Pattern to find assignment entries\n",
        "assg_pattern = r'<assignment>(.*?)</assignment>' # Pattern to match assignment data\n",
        "reel_no_pattern = r'<reel-no>(\\d+)</reel-no>' # Pattern to match reel number\n",
        "frame_no_pattern = r'<frame-no>(.*?)</frame-no>' # Pattern to match frame number\n",
        "update_date_pattern = r'<last-update-date>(.*?)</last-update-date>' # Pattern to match last update date\n",
        "purge_indicator_pattern = r'<purge-indicator>(.*?)</purge-indicator>' # Pattern to match purge indicator\n",
        "date_recorded_pattern = r'<date-recorded>(.*?)</date-recorded>' # Pattern to match date recorded\n",
        "page_count_pattern = r'<page-count>(.*?)</page-count>' # Pattern to match page count\n",
        "correspondent_person_pattern = r'<person-or-organization-name>(.*?)</person-or-organization-name>' # Pattern to match correspondent person/organization name\n",
        "correspondent_address1_pattern = r'<address-1>(.*?)</address-1>' # Pattern to match correspondent address 1\n",
        "correspondent_address2_pattern = r'<address-2>(.*?)</address-2>' # Pattern to match correspondent address 2\n",
        "correspondent_address3_pattern = r'<address-3>(.*?)</address-3>' # Pattern to match correspondent address 3\n",
        "correspondent_address4_pattern = r'<address-4>(.*?)</address-4>' # Pattern to match correspondent address 4\n",
        "correspondent_pattern = r'<correspondent>(.*?)</correspondent>' # Pattern to match correspondent\n",
        "conveyance_text_pattern = r'<conveyance-text>(.*?)</conveyance-text>' # Pattern to match conveyance text\n",
        "assignor_person_pattern = r'<person-or-organization-name>(.*?)</person-or-organization-name>' # Pattern to match assignor person/organization name\n",
        "assignor_state_pattern = r'<state>(.*?)</state>' # Pattern to match assignor state\n",
        "assignor_execution_date_pattern = r'<execution-date>(.*?)</execution-date>' # Pattern to match assignor execution date\n",
        "assignor_legal_entity_text_pattern = r'<legal-entity-text>(.*?)</legal-entity-text>' # Pattern to match assignor legal entity text\n",
        "assignor_date_acknowledged = r'<date-acknowledged>(.*?)</date-acknowledged>' # Pattern to match assignor date acknowledged\n",
        "assignor_nationality_pattern = r'<nationality>(.*?)</nationality>'  # Pattern to match assignor nationality\n",
        "assignor_country_pattern = r'<country-name>(.*?)</country-name>' # Pattern to match assignee country name\n",
        "assignee_person_pattern = r'<person-or-organization-name>(.*?)</person-or-organization-name>' # Pattern to match assignee person/organization name\n",
        "assignee_address1_pattern = r'<address-1>(.*?)</address-1>' # Pattern to match assignee address 1\n",
        "assignee_address2_pattern = r'<address-2>(.*?)</address-2>' # Pattern to match assignee address 2\n",
        "assignee_address3_pattern = r'<address-3>(.*?)</address-3>' # Pattern to match assignee address 3\n",
        "assignee_address4_pattern = r'<address-4>(.*?)</address-4>' # Pattern to match assignee address 4\n",
        "assignee_city_pattern = r'<city>(.*?)</city>' # Pattern to match assignee city\n",
        "assignee_country_pattern = r'<country-name>(.*?)</country-name>' # Pattern to match assignee country name\n",
        "assignee_state_pattern = r'<state>(.*?)</state>' # Pattern to match assignee state\n",
        "assignee_postcode_pattern = r'<postcode>(.*?)</postcode>' # Pattern to match assignee postal code\n",
        "assignee_legal_entity_text_pattern = r'<legal-entity-text>(.*?)</legal-entity-text>' # Pattern to match assignee legal entity text\n",
        "assignee_nationality_pattern = r'<nationality>(.*?)</nationality>' # Pattern to match assignee nationality\n",
        "property_serial_no_pattern = r'<serial-no>(.*?)</serial-no>' # Pattern to match property serial number\n",
        "property_registration_no_pattern = r'<registration-no>(.*?)</registration-no>' # Pattern to match property registration number\n",
        "properties_pattern = r'<properties>(.*?)</properties>' # Pattern to match properties section\n",
        "property_pattern = r'<property>(.*?)</property>' # Pattern to match property entry\n",
        "assignors_pattern = r'<assignors>(.*?)</assignors>' # Pattern to match assignors section\n",
        "assignor_pattern = r'<assignor>(.*?)</assignor>' # Pattern to match assignor entry\n",
        "assignees_pattern = r'<assignees>(.*?)</assignees>' # Pattern to match assignees section\n",
        "assignee_pattern = r'<assignee>(.*?)</assignee>' # Pattern to match assignee entry"
      ],
      "metadata": {
        "id": "96r6V9lhjMcr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTqmBHIKiqK_"
      },
      "source": [
        "These patterns will be used in the next step when reading the files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZ-njkJciqK_"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGcAMvmhiqK_"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "### 4.2. Parsing and Reading Files <a class=\"anchor\" name=\"Read\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llC5D5M3iqK_"
      },
      "source": [
        "In this step, we defined three important functions to facilitate the parsing and reading of XML files containing trademark assignments records.\n",
        "\n",
        "1. The 'unescape_and_convert' function is tasked with decoding Unicode escape sequences and replacing XML special characters such as '&', '<', '>', '\"', and ''' with their respective symbols. This preprocessing is necessary to ensure that the XML data is properly formatted and ready for parsing.\n",
        "\n",
        "2. The 'safe_search' function is designed to safely execute regular expression searches for some fields. It returns the matched group if found or None if the match is unsuccessful, thus preventing errors during data extraction when expected content is missing in the XML structure.\n",
        "\n",
        "3. The 'parse_xml_data' function is the core parsing function responsible for extracting relevant information from the XML data. It starts by unescaping XML special characters using the previously defined function. Then, it iterates through the assignment entries in the XML data using regular expressions defined in step 4.1 to extract specific fields in the XML content.\n",
        "\n",
        "For each assignment entry, data are parsed and organized into structured dictionaries and lists, facilitating easy access and manipulation. Details regarding assignors, assignees, and properties are extracted separately and integrated into each assignment's dictionary. After completing the parsing process, the function outputs a list of dictionaries, each representing a comprehensive assignment entry with all associated details. This parsed data is subsequently read from a specified XML file, processed through the 'parse_xml_data' function, and the first ten entries are printed to validate that the data has been parsed and stored correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD-LSS76iqLA"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to unescape XML special characters\n",
        "def unescape_and_convert(text):\n",
        "\n",
        "    \"\"\"Convert Unicode escape sequences and unescape XML special characters in the string.\"\"\"\n",
        "    # Check if the text is in bytes, decode it to utf-8\n",
        "    if isinstance(text, bytes):\n",
        "        text = text.decode('utf-8')\n",
        "\n",
        "    # Replace XML special characters with their appropriate symbols\n",
        "    text = text.replace('&amp;', '&')\n",
        "    text = text.replace('&lt;', '<')\n",
        "    text = text.replace('&gt;', '>')\n",
        "    text = text.replace('&quot;', '\"')\n",
        "    text = text.replace('&apos;', \"'\")\n",
        "\n",
        "    return text\n",
        "\n",
        "def safe_search(pattern, text):\n",
        "    match = re.search(pattern, text)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Function to parse XML data\n",
        "def parse_xml_data(xml_data):\n",
        "  # Unescape XML special characters\n",
        "  xml_data = unescape_and_convert(xml_data)\n",
        "\n",
        "  # Initialize an empty list to store the parsed data\n",
        "  parsed_data = []\n",
        "\n",
        "  # Find assignment entries using regular expressions\n",
        "  assignment_entries = re.finditer(assg_entry_pattern, xml_data, re.DOTALL)\n",
        "\n",
        "  # Iterate over assignment entries\n",
        "  for entry in assignment_entries:\n",
        "    assignment_data = entry.group(1)\n",
        "    # Initialize an empty dictionary for each assignment\n",
        "    assignment_dict = {}\n",
        "\n",
        "    # Extract assignment data using regular expressions\n",
        "    assignment_dict['reel-no'] = re.search(reel_no_pattern, assignment_data).group(1) if re.search(reel_no_pattern, assignment_data) else None\n",
        "    assignment_dict['frame-no'] = re.search(frame_no_pattern, assignment_data).group(1) if re.search(frame_no_pattern, assignment_data) else None\n",
        "    assignment_dict['last-update-date'] = re.search(update_date_pattern, assignment_data).group(1) if re.search(update_date_pattern, assignment_data) else None\n",
        "    assignment_dict['purge-indicator'] = re.search(purge_indicator_pattern, assignment_data).group(1) if re.search(purge_indicator_pattern, assignment_data) else None\n",
        "    assignment_dict['date-recorded'] = re.search(date_recorded_pattern, assignment_data).group(1) if re.search(date_recorded_pattern, assignment_data) else None\n",
        "    assignment_dict['page-count'] = re.search(page_count_pattern, assignment_data).group(1) if re.search(page_count_pattern, assignment_data) else None\n",
        "\n",
        "    # Initialize an empty dictionary for correspondent information\n",
        "    correspondent_dict = {}\n",
        "\n",
        "    # Extract correspondent block\n",
        "    correspondent_blocks = re.findall(correspondent_pattern, assignment_data, re.DOTALL)\n",
        "\n",
        "    for block in correspondent_blocks:\n",
        "\n",
        "        # Search for the person or organization name within the block\n",
        "        correspondent_name_match = re.search(correspondent_person_pattern, block, re.DOTALL)\n",
        "\n",
        "        if correspondent_name_match:\n",
        "            correspondent_name = correspondent_name_match.group(1).strip() if correspondent_name_match.group(1).strip() else None\n",
        "        else:\n",
        "            correspondent_name = None\n",
        "\n",
        "        correspondent_dict['person-or-organization-name'] = correspondent_name\n",
        "\n",
        "    assignment_dict['correspondent'] = correspondent_dict\n",
        "\n",
        "    assignment_dict['conveyance-text'] = re.search(conveyance_text_pattern, assignment_data).group(1) if re.search(conveyance_text_pattern, assignment_data) else None\n",
        "\n",
        "    assignors_match = re.finditer(assignor_pattern, assignment_data, re.DOTALL)\n",
        "    assignees_match = re.finditer(assignee_pattern, assignment_data, re.DOTALL)\n",
        "    properties_match = re.finditer(property_pattern, assignment_data, re.DOTALL)\n",
        "\n",
        "    # Extract assignors using regular expressions\n",
        "    assignors_list = []\n",
        "    for assignor_match in assignors_match:\n",
        "      assignor_data = assignor_match.group(1)\n",
        "      assignors_list.append({\n",
        "        'person-or-organization-name': safe_search(assignor_person_pattern, assignor_data),\n",
        "        'execution-date': safe_search(assignor_execution_date_pattern, assignor_data),\n",
        "        'legal-entity-text':safe_search(assignor_legal_entity_text_pattern, assignor_data),\n",
        "        'date-acknowledged':safe_search(assignor_date_acknowledged, assignor_data),\n",
        "        'nationality':safe_search(assignor_nationality_pattern, assignor_data),\n",
        "        'state':safe_search(assignor_state_pattern, assignor_data),\n",
        "        'country-name':safe_search(assignor_country_pattern, assignor_data)\n",
        "\n",
        "      })\n",
        "      if assignors_list:\n",
        "        assignment_dict['assignors'] = assignors_list\n",
        "    assignees_list = []\n",
        "    for assignee_match in assignees_match:\n",
        "      assignee_data = assignee_match.group(1)\n",
        "      assignees_list.append({\n",
        "        'person-or-organization-name': safe_search(assignee_person_pattern, assignee_data),\n",
        "        'address-1':safe_search(assignee_address1_pattern, assignee_data),\n",
        "        'address-2':safe_search(assignee_address2_pattern, assignee_data),\n",
        "        'address-4':safe_search(assignee_address4_pattern, assignee_data),\n",
        "        'country-name':safe_search(assignee_country_pattern, assignee_data),\n",
        "        'city':safe_search(assignee_city_pattern, assignee_data),\n",
        "        'state':safe_search(assignee_state_pattern, assignee_data),\n",
        "        'postcode':safe_search(assignee_postcode_pattern, assignee_data),\n",
        "        'legal-entity-text':safe_search(assignee_legal_entity_text_pattern, assignee_data),\n",
        "        'nationality':safe_search(assignee_nationality_pattern, assignee_data)\n",
        "      })\n",
        "      assignment_dict['assignees'] = assignees_list\n",
        "\n",
        "    # Extract properties data using regular expressions\n",
        "      properties_list = []\n",
        "      for property_match in properties_match:\n",
        "        property_data = property_match.group(1)\n",
        "        property_dict = {\n",
        "          'serial-no': safe_search(property_serial_no_pattern, property_data),\n",
        "          'registration-no': safe_search(property_registration_no_pattern, property_data)\n",
        "        }\n",
        "        properties_list.append(property_dict)\n",
        "        assignment_dict['properties'] = properties_list\n",
        "\n",
        "    # Create an assignment entry with assignment data\n",
        "    assignment = {'assignment': assignment_dict}\n",
        "    parsed_data.append(assignment)\n",
        "\n",
        "  return parsed_data\n",
        "\n",
        "# File path to the XML data file\n",
        "data_file_path = '/content/drive/Shareddrives/FIT5196_S1_2024/A1/Students data/Task 1/Group005.txt'\n",
        "\n",
        "# Read the XML data from the file\n",
        "with open(data_file_path, \"r\", encoding = \"utf-8\") as file:\n",
        "    xml_data = file.read()\n",
        "\n",
        "# Parse the XML data to extract assignment information\n",
        "parsed_data = parse_xml_data(xml_data)\n",
        "\n",
        "# Print the first ten elements\n",
        "print(parsed_data[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R5TirbxY3Zw",
        "outputId": "eb377874-aee8-4a0a-af2e-46e2c54b2abe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'assignment': {'reel-no': '6409', 'frame-no': '0912', 'last-update-date': '20180813', 'purge-indicator': 'N', 'date-recorded': '20180809', 'page-count': '5', 'correspondent': {'person-or-organization-name': 'WORLD HOLDINGS INC.'}, 'conveyance-text': 'ASSIGNS THE ENTIRE INTEREST', 'assignors': [{'person-or-organization-name': 'ISODIOL INTERNATIONAL INC', 'execution-date': '20180702', 'legal-entity-text': 'CORPORATION', 'date-acknowledged': None, 'nationality': 'CANADA', 'state': None, 'country-name': None}], 'assignees': [{'person-or-organization-name': 'WORLD HOLDINGS, INC.', 'address-1': '1712 PIONEER AVENUE SUITE 500', 'address-2': None, 'address-4': None, 'country-name': None, 'city': 'CHEYENNE', 'state': 'WYOMING', 'postcode': '82001', 'legal-entity-text': 'CORPORATION', 'nationality': 'WYOMING'}], 'properties': [{'serial-no': '77962789', 'registration-no': '4354279'}]}}, {'assignment': {'reel-no': '3792', 'frame-no': '0180', 'last-update-date': '20080609', 'purge-indicator': 'N', 'date-recorded': '20080609', 'page-count': '4', 'correspondent': {'person-or-organization-name': 'CHRISTIE, PARKER & HALE, LLP'}, 'conveyance-text': 'ASSIGNS THE ENTIRE INTEREST', 'assignors': [{'person-or-organization-name': 'EARTH ISLAND', 'execution-date': '20080506', 'legal-entity-text': 'CORPORATION', 'date-acknowledged': None, 'nationality': 'CALIFORNIA', 'state': None, 'country-name': None}], 'assignees': [{'person-or-organization-name': 'OLD FRIENDS HOLDINGS, LLC', 'address-1': '9201 OWENSMOUTH AVENUE', 'address-2': None, 'address-4': None, 'country-name': None, 'city': 'CHATSWORTH', 'state': 'CALIFORNIA', 'postcode': '91311', 'legal-entity-text': 'LIMITED LIABILITY COMPANY', 'nationality': 'CALIFORNIA'}], 'properties': [{'serial-no': '78244677', 'registration-no': '3012336'}]}}, {'assignment': {'reel-no': '449', 'frame-no': '0199', 'last-update-date': '19920828', 'purge-indicator': 'N', 'date-recorded': '19820816', 'page-count': '2', 'correspondent': {'person-or-organization-name': 'KEGAN, KEGAN, ET AL.'}, 'conveyance-text': 'CHANGE OF NAME 19820514', 'assignors': [{'person-or-organization-name': 'PRACTICAL HOLDING , INC.', 'execution-date': '19820514', 'legal-entity-text': 'UNKNOWN', 'date-acknowledged': None, 'nationality': None, 'state': None, 'country-name': None}], 'assignees': [{'person-or-organization-name': 'PRACTICAL RENT-A-CAR CORPORATION', 'address-1': None, 'address-2': None, 'address-4': None, 'country-name': None, 'city': None, 'state': None, 'postcode': None, 'legal-entity-text': 'UNKNOWN', 'nationality': None}], 'properties': [{'serial-no': '73329853', 'registration-no': '1290456'}]}}, {'assignment': {'reel-no': '7518', 'frame-no': '0248', 'last-update-date': '20220111', 'purge-indicator': 'N', 'date-recorded': '20211207', 'page-count': '4', 'correspondent': {'person-or-organization-name': 'ROBERT FRIEDHOFF'}, 'conveyance-text': 'DOMESTICATION', 'assignors': [{'person-or-organization-name': 'TROPICAL SHIPPING AND CONSTRUCTION COMPANY LIMITED', 'execution-date': '20201231', 'legal-entity-text': 'CORPORATION', 'date-acknowledged': None, 'nationality': 'CAYMAN ISLANDS', 'state': None, 'country-name': None}], 'assignees': [{'person-or-organization-name': 'TROPICAL SHIPPING AND CONSTRUCTION COMPANY LIMITED, LLC', 'address-1': '501 AVENUE P', 'address-2': 'LEGAL DEPARTMENT', 'address-4': None, 'country-name': None, 'city': 'RIVIERA BEACH', 'state': 'FLORIDA', 'postcode': '33404', 'legal-entity-text': 'LIMITED LIABILITY COMPANY', 'nationality': 'DELAWARE'}], 'properties': [{'serial-no': '78539796', 'registration-no': '3032258'}, {'serial-no': '75119414', 'registration-no': '2139641'}, {'serial-no': '75119416', 'registration-no': '2157447'}]}}, {'assignment': {'reel-no': '5852', 'frame-no': '0631', 'last-update-date': '20160830', 'purge-indicator': 'N', 'date-recorded': '20160810', 'page-count': '7', 'correspondent': {'person-or-organization-name': 'PAUL TATE'}, 'conveyance-text': 'SECOND SUPPLEMENT TO INTELLECTUAL PROPERTY SECURITY AGREEMENT', 'assignors': [{'person-or-organization-name': 'OUTBRAIN INC.', 'execution-date': '20160809', 'legal-entity-text': 'CORPORATION', 'date-acknowledged': None, 'nationality': 'DELAWARE', 'state': None, 'country-name': None}], 'assignees': [{'person-or-organization-name': 'SILICON VALLEY BANK', 'address-1': '3003 TASMAN DRIVE', 'address-2': None, 'address-4': None, 'country-name': None, 'city': 'SANTA CLARA', 'state': 'CALIFORNIA', 'postcode': '95054', 'legal-entity-text': 'CORPORATION', 'nationality': 'CALIFORNIA'}], 'properties': [{'serial-no': '87045380', 'registration-no': None}, {'serial-no': '86649618', 'registration-no': '5032852'}]}}, {'assignment': {'reel-no': '3330', 'frame-no': '0215', 'last-update-date': '20061121', 'purge-indicator': 'N', 'date-recorded': '20051208', 'page-count': '2', 'correspondent': {'person-or-organization-name': 'VION B.V.'}, 'conveyance-text': 'CHANGE OF NAME', 'assignors': [{'person-or-organization-name': 'BESTMEAT COMPANY B.V.', 'execution-date': '20050804', 'legal-entity-text': 'UNKNOWN', 'date-acknowledged': None, 'nationality': 'NETHERLANDS', 'state': None, 'country-name': None}], 'assignees': [{'person-or-organization-name': 'VION B.V.', 'address-1': 'NCB WEG 10', 'address-2': None, 'address-4': None, 'country-name': 'NETHERLANDS', 'city': 'NL-5681 RH BEST', 'state': None, 'postcode': None, 'legal-entity-text': 'UNKNOWN', 'nationality': 'BENELUX'}], 'properties': [{'serial-no': '79017584', 'registration-no': '3174347'}]}}, {'assignment': {'reel-no': '1491', 'frame-no': '0578', 'last-update-date': '19970904', 'purge-indicator': 'N', 'date-recorded': '19960624', 'page-count': '15', 'correspondent': {'person-or-organization-name': 'WINSTON & STRAWN'}, 'conveyance-text': 'CONTINUING SECURITY INTEREST AND COLLATERAL ASSIGNMENTS OF PATENTS, TRADEMARKS, COPYRIGHTS AND LICENSES.', 'assignors': [{'person-or-organization-name': 'BROTHERS GOURMET COFFEES, INC.', 'execution-date': '19960529', 'legal-entity-text': 'CORPORATION', 'date-acknowledged': None, 'nationality': 'DELAWARE', 'state': None, 'country-name': None}], 'assignees': [{'person-or-organization-name': 'SANWA BUSINESS CREDIT CORPORATION (AS AGENT)', 'address-1': None, 'address-2': '1 SOUTH WACKER', 'address-4': None, 'country-name': None, 'city': 'CHICAGO', 'state': 'ILLINOIS', 'postcode': '60606', 'legal-entity-text': 'CORPORATION', 'nationality': 'DELAWARE'}], 'properties': [{'serial-no': '74510607', 'registration-no': '2008872'}, {'serial-no': '74426199', 'registration-no': '2093345'}, {'serial-no': '74275436', 'registration-no': '1842662'}, {'serial-no': '74275897', 'registration-no': '1850797'}, {'serial-no': '73485773', 'registration-no': '1376149'}, {'serial-no': '74236312', 'registration-no': '1830463'}, {'serial-no': '74235570', 'registration-no': '1818630'}, {'serial-no': '74296364', 'registration-no': '1800959'}, {'serial-no': '74297056', 'registration-no': '1758590'}, {'serial-no': '74107903', 'registration-no': '1733365'}, {'serial-no': '74295261', 'registration-no': '1840038'}, {'serial-no': '73580287', 'registration-no': '1438240'}, {'serial-no': '73392617', 'registration-no': '1279137'}, {'serial-no': '73838042', 'registration-no': '1630224'}, {'serial-no': '74225485', 'registration-no': '1716212'}, {'serial-no': '74263359', 'registration-no': '1845204'}, {'serial-no': '73837100', 'registration-no': '1629328'}, {'serial-no': '73520672', 'registration-no': '1387679'}, {'serial-no': '73805650', 'registration-no': '1587002'}, {'serial-no': '73570320', 'registration-no': '1408798'}, {'serial-no': '73624950', 'registration-no': '1510540'}, {'serial-no': '74198567', 'registration-no': '1705257'}, {'serial-no': '74288764', 'registration-no': '1818538'}, {'serial-no': '73580309', 'registration-no': '1406041'}, {'serial-no': '73512561', 'registration-no': '1386960'}, {'serial-no': '74229806', 'registration-no': '1736859'}, {'serial-no': '74221445', 'registration-no': '1712005'}]}}, {'assignment': {'reel-no': '1599', 'frame-no': '0606', 'last-update-date': '19970731', 'purge-indicator': 'N', 'date-recorded': '19970613', 'page-count': '5', 'correspondent': {'person-or-organization-name': 'DEVEAU, COLTON & MARQUIS'}, 'conveyance-text': 'ASSIGNS THE ENTIRE INTEREST', 'assignors': [{'person-or-organization-name': 'LA CAZUELA CORPORATION', 'execution-date': '19951229', 'legal-entity-text': 'CORPORATION', 'date-acknowledged': None, 'nationality': 'GEORGIA', 'state': None, 'country-name': None}], 'assignees': [{'person-or-organization-name': 'RODRIGUEZ, LUIS C.', 'address-1': None, 'address-2': '5405 HAMPSTEAD WAY', 'address-4': None, 'country-name': None, 'city': 'DULUTH', 'state': 'GEORGIA', 'postcode': '30155', 'legal-entity-text': 'INDIVIDUAL', 'nationality': 'UNITED STATES'}], 'properties': [{'serial-no': '74138719', 'registration-no': '1667115'}]}}, {'assignment': {'reel-no': '622', 'frame-no': '0605', 'last-update-date': '19901031', 'purge-indicator': 'N', 'date-recorded': '19881024', 'page-count': '3', 'correspondent': {'person-or-organization-name': 'LOWENSTEIN, SANDLER, ET AL.'}, 'conveyance-text': 'ASSIGNS THE ENTIRE INTEREST AND THE GOODWILL', 'assignors': [{'person-or-organization-name': 'SCHOTTENSTEIN STORES CORPORATION', 'execution-date': '19881018', 'legal-entity-text': 'CORPORATION', 'date-acknowledged': None, 'nationality': 'DELAWARE', 'state': 'OHIO', 'country-name': None}], 'assignees': [{'person-or-organization-name': 'R & S/STRAUSS ASSOCIATED', 'address-1': None, 'address-2': '1835 BURNET AVENUE', 'address-4': None, 'country-name': None, 'city': 'UNION', 'state': 'NEW JERSEY', 'postcode': '07083', 'legal-entity-text': 'PARTNERSHIP', 'nationality': None}], 'properties': [{'serial-no': '71616836', 'registration-no': '605822'}, {'serial-no': '73670274', 'registration-no': '1478109'}]}}, {'assignment': {'reel-no': '818', 'frame-no': '0731', 'last-update-date': '19911120', 'purge-indicator': 'N', 'date-recorded': '19911007', 'page-count': '5', 'correspondent': {'person-or-organization-name': 'JOHN M. BENASSI'}, 'conveyance-text': 'ASSIGNS THE ENTIRE INTEREST AND THE GOODWILL', 'assignors': [{'person-or-organization-name': 'AMFAC, INC.', 'execution-date': '19910729', 'legal-entity-text': 'CORPORATION', 'date-acknowledged': None, 'nationality': 'HAWAII', 'state': None, 'country-name': None}], 'assignees': [{'person-or-organization-name': 'LIBERTY HOUSE, INC.', 'address-1': None, 'address-2': 'P.O. BOX 2690', 'address-4': None, 'country-name': None, 'city': 'HONOLULU', 'state': 'HAWAII', 'postcode': '96845', 'legal-entity-text': 'CORPORATION', 'nationality': 'HAWAII'}], 'properties': [{'serial-no': '72352923', 'registration-no': '919577'}]}}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtwS6ttqiqLA"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "### 4.3. Transform to JSON Format <a class=\"anchor\" name=\"latin\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IJ63oV9iqLA"
      },
      "source": [
        "In this step, once again, we defined two functions for handling specific tasks as follows:\n",
        "\n",
        "1. The 'remove_title_from_person_name' function is designed to cleanse personal names by removing the titles. It operates by checking whether a particular assignor/assignee is labeled as an individual or an organization; if NOT labeled as an individual, it bypasses the cleansing. Otherwise, it utilizes a predefined list of titles, which it removes from the name to ensure consistency and professionalism in data representation.\n",
        "\n",
        "2. The 'get_country' function extracts the country information from an entry's dictionary. It prioritizes the 'country-name', 'state', and 'nationality' keys to ascertain the most accurate country assignment. This function includes normalization mappings to handle variations such as 'UNITED STATES' to 'USA' and returns 'NA' for cases where neither 'country-name', 'state', nor 'nationality' is provided.\n",
        "\n",
        "Consequently, we further process the parsed XML data from the previous steps to transform it into a structured JSON format. The process involves using the defined functions to handle specific tasks such as removing titles from person names and extracting country information from assignor/assignee data. Upon parsing the XML data and extracting relevant assignment details, we embark on transforming this data into a structured JSON format. Each entry is transformed into a dictionary format, with fields organized systematically. Assignment entry details, assignors, assignees, and properties information are appropriately structured within each entry to be further processed in the next step. Lastly, we printed the first five elements of the transformed data to verify the transformation results and inspect the JSON structure."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_title_from_person_name(name, legal_entity_text):\n",
        "\n",
        "    # Define a list for titles to be removed\n",
        "    title_list = [\"Mr\", \"Mrs\", \"Miss\", \"Ms\", \"Mx\", \"Sir\", \"Dame\", \"Dr\", \"Cllr\", \"Lady\", \"Lord\"]\n",
        "    title_list_with_period = [title + '.' for title in title_list]\n",
        "    title_list = [title.upper() for title in title_list]\n",
        "\n",
        "    title_list_combined = title_list + title_list_with_period\n",
        "    title_list_combined = [title.upper() for title in title_list_combined]\n",
        "\n",
        "    # Check if the legal entity is not an individual\n",
        "    if (legal_entity_text or 'NA').upper() != \"INDIVIDUAL\":\n",
        "        return name  # Return the name as is if not an individual\n",
        "\n",
        "    # Split the name into parts, remove any dots, and convert each to uppercase for comparison\n",
        "    name_parts = name.split()\n",
        "    cleaned_name_parts = []\n",
        "    for part in name_parts:\n",
        "        # Check if the part is a title and should be removed\n",
        "        if part.upper() not in title_list_combined:\n",
        "            cleaned_name_parts.append(part)\n",
        "\n",
        "    # Reconstruct the name without the titles\n",
        "    cleaned_name = ' '.join(cleaned_name_parts)\n",
        "    # Properly handle commas and trailing spaces\n",
        "    cleaned_name = cleaned_name.strip(', ')\n",
        "\n",
        "    return cleaned_name\n",
        "\n",
        "# Function to get the country from an assignor/assignee\n",
        "def get_country(entry):\n",
        "    country_normalization = {\n",
        "        'UNITED STATES': 'USA',\n",
        "        'UNITED KINGDOM': 'UK',\n",
        "        'ENGLAND':'UK',\n",
        "        'USA': 'USA'\n",
        "    }\n",
        "\n",
        "    state_to_country = {\n",
        "\n",
        "    # USA states\n",
        "    'ALABAMA': 'USA', 'ALASKA': 'USA', 'ARIZONA': 'USA', 'ARKANSAS': 'USA', 'CALIFORNIA': 'USA',\n",
        "    'COLORADO': 'USA', 'CONNECTICUT': 'USA', 'DELAWARE': 'USA', 'FLORIDA': 'USA', 'GEORGIA': 'USA',\n",
        "    'HAWAII': 'USA', 'IDAHO': 'USA', 'ILLINOIS': 'USA', 'INDIANA': 'USA', 'IOWA': 'USA', 'KANSAS': 'USA',\n",
        "    'KENTUCKY': 'USA', 'LOUISIANA': 'USA', 'MAINE': 'USA', 'MARYLAND': 'USA', 'MASSACHUSETTS': 'USA',\n",
        "    'MICHIGAN': 'USA', 'MINNESOTA': 'USA', 'MISSISSIPPI': 'USA', 'MISSOURI': 'USA', 'MONTANA': 'USA',\n",
        "    'NEBRASKA': 'USA', 'NEVADA': 'USA', 'NEW HAMPSHIRE': 'USA', 'NEW JERSEY': 'USA', 'NEW MEXICO': 'USA',\n",
        "    'NEW YORK': 'USA', 'NORTH CAROLINA': 'USA', 'NORTH DAKOTA': 'USA', 'OHIO': 'USA', 'OKLAHOMA': 'USA',\n",
        "    'OREGON': 'USA', 'PENNSYLVANIA': 'USA', 'RHODE ISLAND': 'USA', 'SOUTH CAROLINA': 'USA',\n",
        "    'SOUTH DAKOTA': 'USA', 'TENNESSEE': 'USA', 'TEXAS': 'USA', 'UTAH': 'USA', 'VERMONT': 'USA',\n",
        "    'VIRGINIA': 'USA', 'WASHINGTON': 'USA','DISTRICT OF COLUMBIA':'USA', 'WEST VIRGINIA': 'USA', 'WISCONSIN': 'USA', 'WYOMING': 'USA',\n",
        "\n",
        "    # UK regions\n",
        "    'ENGLAND': 'UK', 'SCOTLAND': 'UK', 'WALES': 'UK', 'NORTHERN IRELAND': 'UK',\n",
        "\n",
        "    # Canadian provinces\n",
        "    'ONTARIO': 'CANADA', 'QUEBEC': 'CANADA', 'BRITISH COLUMBIA': 'CANADA', 'ALBERTA': 'CANADA',\n",
        "    'MANITOBA': 'CANADA', 'SASKATCHEWAN': 'CANADA', 'NOVA SCOTIA': 'CANADA', 'NEW BRUNSWICK': 'CANADA',\n",
        "    'NEWFOUNDLAND AND LABRADOR': 'CANADA', 'PRINCE EDWARD ISLAND': 'CANADA', 'NORTHWEST TERRITORIES': 'CANADA',\n",
        "    'YUKON': 'CANADA', 'NUNAVUT': 'CANADA'\n",
        "}\n",
        "\n",
        "    # Check for direct country name\n",
        "    country = entry.get('country-name')\n",
        "    if country is not None:\n",
        "      country = country.upper()  # Convert to uppercase to handle case sensitivity\n",
        "      if country in country_normalization:\n",
        "        return country_normalization[country]  # Return the normalized country name\n",
        "      else:\n",
        "        return country  # Return the country name as is\n",
        "\n",
        "\n",
        "    # Check for state as next option using the mapping\n",
        "    state = entry.get('state')\n",
        "    if state and state.upper() in state_to_country:\n",
        "        return state_to_country[state.upper()]\n",
        "\n",
        "    # Finally, check for nationality if state doesn't give a conclusive result\n",
        "    nationality = entry.get('nationality')\n",
        "    if nationality and nationality.upper() in state_to_country:\n",
        "      return state_to_country[nationality.upper()]\n",
        "    elif nationality =='NOT PROVIDED':\n",
        "      nationality='NA'\n",
        "      return nationality\n",
        "    elif nationality in country_normalization:\n",
        "      return country_normalization[nationality]\n",
        "    elif nationality!=None:\n",
        "      return nationality\n",
        "\n",
        "    # Return 'NA' if no country information is found\n",
        "    return 'NA'\n",
        "\n",
        "# Initialize an empty dictionary for transformed data\n",
        "transformed_data = {}\n",
        "\n",
        "# Iterate over the parsed data to transform and populate the transformed_data dictionary\n",
        "for entry in parsed_data:\n",
        "  # Initialize an empty dictionary for each entry transformation\n",
        "  transformed_entry = {}\n",
        "\n",
        "  # Concatenate reel-no and frame-no for rf_id\n",
        "  rf_id = f\"{entry['assignment']['reel-no']}{entry['assignment']['frame-no']}\"\n",
        "\n",
        "  # Transform and populate fields for the current entry\n",
        "  last_update_date = entry['assignment'].get('last-update-date')\n",
        "  transformed_entry['last-update-date'] = f\"{last_update_date[:4]}-{last_update_date[4:6]}-{last_update_date[6:]}\" # Format last-update-date\n",
        "  transformed_entry['conveyance-text'] = entry['assignment'].get('conveyance-text') or 'NA'\n",
        "  transformed_entry['correspondent-party'] = entry['assignment']['correspondent'].get('person-or-organization-name') or 'NA'\n",
        "\n",
        "  # Transform assignors-info\n",
        "  assignors_info = []\n",
        "  # Iterate over the assignors list\n",
        "  for assignor in entry['assignment']['assignors']:\n",
        "    date_acknowledged = assignor.get('date-acknowledged', 'NA')\n",
        "    execution_date = assignor.get('execution-date', 'NA')\n",
        "    assignor_info = {\n",
        "      'party-name': remove_title_from_person_name(assignor['person-or-organization-name'],assignor.get('legal-entity-text', 'NA')),\n",
        "      'date-acknowledged' : date_acknowledged if date_acknowledged == 'NA' else f\"{date_acknowledged[:4]}-{date_acknowledged[4:6]}-{date_acknowledged[6:]}\" if date_acknowledged else 'NA',\n",
        "      'execution-date': execution_date if execution_date == 'NA' else f\"{execution_date[:4]}-{execution_date[4:6]}-{execution_date[6:]}\" if execution_date else 'NA',\n",
        "      'country': get_country(assignor), # Get country for assignor\n",
        "      'legal-entity-text': assignor.get('legal-entity-text') or 'NA'\n",
        "    }\n",
        "    # Append assignor to assignors_info list\n",
        "    assignors_info.append(assignor_info)\n",
        "\n",
        "  # Transform assignees-info\n",
        "  assignees_info = []\n",
        "  # Iterate over the assignors list\n",
        "  for assignee in entry['assignment']['assignees']:\n",
        "    assignee_info = {\n",
        "      'party-name': remove_title_from_person_name(assignee['person-or-organization-name'],assignee.get('legal-entity-text', 'NA')), # Remove the name titles\n",
        "      'country': get_country(assignee), # Get the assignee country\n",
        "      'legal-entity-text': assignee.get('legal-entity-text') or 'NA'\n",
        "    }\n",
        "    # Append assignee to assignees_info list\n",
        "    assignees_info.append(assignee_info)\n",
        "\n",
        "  # Populate transformed entry fields\n",
        "  transformed_entry['assignors-info'] = assignors_info\n",
        "  transformed_entry['assignees-info'] = assignees_info\n",
        "  transformed_entry['property-count'] = str(len(entry['assignment']['properties']))\n",
        "\n",
        "  # Assign transformed_entry to the rf_id key in transformed_data\n",
        "  transformed_data[rf_id] = transformed_entry\n",
        "\n",
        "# Print the first five elements of the transformed data\n",
        "for i, (rf_id, entry) in enumerate(list(transformed_data.items())[:5], start=1):\n",
        "    print(f\"\\n\")\n",
        "    for key, value in entry.items():\n",
        "        print(f\"  {key}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBxDZoYOkGfz",
        "outputId": "77fb94d2-8ecf-4220-9a9d-62d7262bf952"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "  last-update-date: 2018-08-13\n",
            "  conveyance-text: ASSIGNS THE ENTIRE INTEREST\n",
            "  correspondent-party: WORLD HOLDINGS INC.\n",
            "  assignors-info: [{'party-name': 'ISODIOL INTERNATIONAL INC', 'date-acknowledged': 'NA', 'execution-date': '2018-07-02', 'country': 'CANADA', 'legal-entity-text': 'CORPORATION'}]\n",
            "  assignees-info: [{'party-name': 'WORLD HOLDINGS, INC.', 'country': 'USA', 'legal-entity-text': 'CORPORATION'}]\n",
            "  property-count: 1\n",
            "\n",
            "\n",
            "  last-update-date: 2008-06-09\n",
            "  conveyance-text: ASSIGNS THE ENTIRE INTEREST\n",
            "  correspondent-party: CHRISTIE, PARKER & HALE, LLP\n",
            "  assignors-info: [{'party-name': 'EARTH ISLAND', 'date-acknowledged': 'NA', 'execution-date': '2008-05-06', 'country': 'USA', 'legal-entity-text': 'CORPORATION'}]\n",
            "  assignees-info: [{'party-name': 'OLD FRIENDS HOLDINGS, LLC', 'country': 'USA', 'legal-entity-text': 'LIMITED LIABILITY COMPANY'}]\n",
            "  property-count: 1\n",
            "\n",
            "\n",
            "  last-update-date: 1992-08-28\n",
            "  conveyance-text: CHANGE OF NAME 19820514\n",
            "  correspondent-party: KEGAN, KEGAN, ET AL.\n",
            "  assignors-info: [{'party-name': 'PRACTICAL HOLDING , INC.', 'date-acknowledged': 'NA', 'execution-date': '1982-05-14', 'country': 'NA', 'legal-entity-text': 'UNKNOWN'}]\n",
            "  assignees-info: [{'party-name': 'PRACTICAL RENT-A-CAR CORPORATION', 'country': 'NA', 'legal-entity-text': 'UNKNOWN'}]\n",
            "  property-count: 1\n",
            "\n",
            "\n",
            "  last-update-date: 2022-01-11\n",
            "  conveyance-text: DOMESTICATION\n",
            "  correspondent-party: ROBERT FRIEDHOFF\n",
            "  assignors-info: [{'party-name': 'TROPICAL SHIPPING AND CONSTRUCTION COMPANY LIMITED', 'date-acknowledged': 'NA', 'execution-date': '2020-12-31', 'country': 'CAYMAN ISLANDS', 'legal-entity-text': 'CORPORATION'}]\n",
            "  assignees-info: [{'party-name': 'TROPICAL SHIPPING AND CONSTRUCTION COMPANY LIMITED, LLC', 'country': 'USA', 'legal-entity-text': 'LIMITED LIABILITY COMPANY'}]\n",
            "  property-count: 3\n",
            "\n",
            "\n",
            "  last-update-date: 2016-08-30\n",
            "  conveyance-text: SECOND SUPPLEMENT TO INTELLECTUAL PROPERTY SECURITY AGREEMENT\n",
            "  correspondent-party: PAUL TATE\n",
            "  assignors-info: [{'party-name': 'OUTBRAIN INC.', 'date-acknowledged': 'NA', 'execution-date': '2016-08-09', 'country': 'USA', 'legal-entity-text': 'CORPORATION'}]\n",
            "  assignees-info: [{'party-name': 'SILICON VALLEY BANK', 'country': 'USA', 'legal-entity-text': 'CORPORATION'}]\n",
            "  property-count: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g9k9Fb8iqLB"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "KVwmp1LfiqLE"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "## 5.  Writing to CSV/JSON File <a class=\"anchor\" name=\"write\"></a>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we write the processed data from the previous step, which has already been stored in a JSON format, to JSON file."
      ],
      "metadata": {
        "id": "4bWpl3u5z4pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the transformed_data to a JSON file using json.dump\n",
        "with open('task1_005.json', 'w', encoding = 'utf-8') as json_file:\n",
        "    json.dump(transformed_data, json_file, indent = 4) # Specify an indent of 4 for readability"
      ],
      "metadata": {
        "id": "LpA538zmVt0E"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0WT10TJiqLE"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "3XcaJBATiqLE"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "### 5.1. Verification - using the sample files <a class=\"anchor\" name=\"test_xml\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEg_xQdXiqLF"
      },
      "source": [
        "Finally, we test the output JSON file using the test script provided on Google Drive to ensure the output file passes all the checks and does not raise any errors.   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "groupnum=input(\"Please input your group number:\")\n",
        "with open(\"task1_{}.json\".format(groupnum.zfill(3)),\"r\") as file:\n",
        "    content=file.read()\n",
        "    try:\n",
        "        data=json.loads(content)\n",
        "    except:\n",
        "        raise TypeError(\"Invalid json: unable to load data!\")\n",
        "    try:\n",
        "        df=pd.DataFrame(data)\n",
        "        table = pd.pivot_table(df, values=df.columns, columns=df.index, aggfunc=\"max\")\n",
        "    except Exception as e:\n",
        "        raise ValueError(\"Invalid daya structure: check your data structure!\")\n",
        "    allowedvariance={\"assignors_info\":\"assignors-info\",\"assignees_info\":\"assignees-info\",\n",
        "                     \"last-updated-date\":'last-updated-date',\"correspondent_party\":\"correspondent-party\"}\n",
        "    studentcols=[]\n",
        "    for each in df.index.to_list():\n",
        "        if each in allowedvariance.keys():\n",
        "            studentcols.append(allowedvariance[each])\n",
        "        else:\n",
        "            studentcols.append(each)\n",
        "\n",
        "    indexnames=['assignees-info', 'assignors-info', 'conveyance-text',\n",
        "       'correspondent-party', 'last-update-date', 'property-count']\n",
        "    assert set(indexnames)==set(studentcols), \"Invalid key in json: check your json keys!\"\n",
        "    print(\"Task 1 json file passed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3WUDMKo2pgs",
        "outputId": "73019936-1675-4824-950d-583b339c25d8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please input your group number:005\n",
            "Task 1 json file passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20RDw_JDiqLF"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cO8vwKqkiqLF"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "## 6. Summary <a class=\"anchor\" name=\"summary\"></a>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QdX7ozQiqLF"
      },
      "source": [
        "In this assignment, we demonstrated the extraction, parsing, transformation, and validation of semi-structured data from trademark assignments records. The primary objective was to convert raw text data stored in XML format into a structured JSON format which is suitable for further analysis and processing. The initial phase included examining the raw data to identify patterns and data elements. The data was parsed from XML format to extract details regarding the assignments and transformed into a structured JSON format using regular expressions (regex) and custom functions for specific tasks such as removing titles from names and mapping locations to countries. Once the structured data was written to a JSON file, a test script was implemented to check key indices and validate the JSON structure against expectations, ensuring the correctness of the output file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnASfTmniqLF"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li7bchX9iqLF"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "## 7. References <a class=\"anchor\" name=\"Ref\"></a>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkWuWC3NiqLF"
      },
      "source": [
        "\n",
        "\n",
        "[1]Python Regex, https://www.geeksforgeeks.org/python-regex/.\n",
        "\n",
        "....\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVyuz4LciqLG"
      },
      "source": [
        "## --------------------------------------------------------------------------------------------------------------------------"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}